{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1> BME548 Final Project Code </h1>\n",
        "Emma Nisbet, Mengde Liu, and Talya Jeter"
      ],
      "metadata": {
        "id": "MDtZBsU1204B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, losses, Model\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras.utils import plot_model\n",
        "tf.keras.backend.set_image_data_format(\"channels_last\")\n",
        "import cv2\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "d6wvYHkxjR1Y"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hI_dt5KQLWZk",
        "outputId": "402471b8-f09f-4d38-ea50-fda0fcc971dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "#connect to drive, where we saved the dataset images\n",
        "drive.mount('/content/drive/')\n",
        "os.chdir('/content/drive/MyDrive/BME 548L Group')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDG3_2OGLd5s",
        "outputId": "49b8e03b-494c-45f3-eb57-67856d686eee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " archive\t\t\t\t   General_aim.pdf\n",
            " checkpoint\t\t\t\t  'Ghosting Simulation.ipynb'\n",
            " entire_model.png\t\t\t  'Project Proposal.gdoc'\n",
            " final_model_weights.data-00000-of-00001   ResNet50_Modeling.ipynb\n",
            " final_model_weights.h5\t\t\t   ResNet50_Modeling_testing_physical_layer.ipynb\n",
            " final_model_weights.index\t\t   ResNet50_Modeling_validate.ipynb\n",
            "'Final Paper.gdoc'\t\t\t   resnet50_model.png\n",
            "'Final Presentation.gslides'\t\t  'Training Layer.ipynb'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "DJDl0ajvMmhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = r'/content/drive/MyDrive/BME 548L Group/archive/Training'\n",
        "test_data_dir = r'/content/drive/MyDrive/BME 548L Group/archive/Testing'"
      ],
      "metadata": {
        "id": "0bO71I4UL-xK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_folder(folder):\n",
        "  '''\n",
        "  Read in images from folders, convert to grayscale, crop to 128 * 128, and normalize.\n",
        "  Return images and labels as numpy arrays.\n",
        "  '''\n",
        "\n",
        "  images = []\n",
        "  labels = []\n",
        "  # Iterate through the folders in the parent directory\n",
        "  for folder_name in os.listdir(folder):\n",
        "      folder_path = os.path.join(folder, folder_name)\n",
        "\n",
        "      # Ensure that it's a directory (not a file)\n",
        "      if os.path.isdir(folder_path):\n",
        "          # Use the folder name as the label\n",
        "          label = folder_name\n",
        "\n",
        "          # Change directory to the folder containing the images\n",
        "          os.chdir(folder_path)\n",
        "\n",
        "          # Loop through the files in the directory\n",
        "          for filename in tqdm.tqdm(os.listdir()):\n",
        "              if filename.endswith('.jpg'):\n",
        "                  img = cv2.imread(filename)\n",
        "                  #Turn to grayscale\n",
        "                  img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "                  # Normalize\n",
        "                  img = cv2.resize(img, (128, 128)) /255.0\n",
        "                  # Append the image to the training list\n",
        "                  images.append(img)\n",
        "                  # Append the label to the training label list\n",
        "                  labels.append(label)\n",
        "  return np.array(images), np.array(labels)\n",
        "\n",
        "\n",
        "print(\"load training...\")\n",
        "X_train, y_train = load_images_from_folder(train_data_dir)\n",
        "\n",
        "print(\"load testing...\")\n",
        "X_test, y_test = load_images_from_folder(test_data_dir)\n",
        "\n",
        "\n",
        "# Turn y labels into one hot encoding ex: notumor = [0, 0, 1, 0]\n",
        "classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "y_train_new = []\n",
        "for i in y_train:\n",
        "    y_train_new.append(classes.index(i))\n",
        "y_train = tf.keras.utils.to_categorical(y_train_new)\n",
        "\n",
        "y_test_new = []\n",
        "for i in y_test:\n",
        "    y_test_new.append(classes.index(i))\n",
        "y_test = tf.keras.utils.to_categorical(y_test_new)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u2RDaAt0wRJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "fvT_r9Wj03Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example of training set image\n",
        "plt.imshow(X_train[10], cmap='gray')\n",
        "print(\"label = \", y_train[10])"
      ],
      "metadata": {
        "id": "w92lTOUTzi-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "2-poGhBw2FY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ghost_kernel(kx, ky, direction):\n",
        "  '''\n",
        "  Create a ghosting mask of shape (kx, ky) for a given kernel size and direction.\n",
        "  '''\n",
        "  mask = np.ones((kx, ky))\n",
        "  if direction == \"vertical\":\n",
        "    kernel_size = 4\n",
        "    delA = 0.75\n",
        "    dx = 4\n",
        "    for i in range(0, kx, kernel_size):\n",
        "        for j in range(0, ky, kernel_size):\n",
        "            if  (i/kernel_size)% dx==0:\n",
        "                mask[i:i+kernel_size,j:j+kernel_size] = mask[i:i+kernel_size,j:j+kernel_size]-delA\n",
        "  elif direction == \"horizontal\":\n",
        "    kernel_size = 4\n",
        "    delA = 0.75\n",
        "    dx = 4\n",
        "    for i in range(0, kx, kernel_size):\n",
        "        for j in range(0, ky, kernel_size):\n",
        "            if (j/kernel_size)%dx ==0:\n",
        "                mask[i:i+kernel_size,j:j+kernel_size] = mask[i:i+kernel_size,j:j+kernel_size]-delA\n",
        "  elif direction == \"diagonal\":\n",
        "    kernel_size = 2\n",
        "    delA = 0.75\n",
        "    dx = 2\n",
        "    for i in range(0, kx, kernel_size):\n",
        "        for j in range(0, ky, kernel_size):\n",
        "            if  (i/kernel_size)% dx==0 and (j/kernel_size)%dx ==0:\n",
        "                mask[i:i+kernel_size,j:j+kernel_size] = mask[i:i+kernel_size,j:j+kernel_size]-delA\n",
        "  return mask\n",
        "\n",
        "def apply_ghosting(img, direction):\n",
        "  # Perform Fourier transform\n",
        "  k_space_data = np.fft.fft2(img)\n",
        "  # Shift zero frequency component to the center\n",
        "  k_space_data = np.fft.fftshift(k_space_data)\n",
        "\n",
        "  # Get dimensions of k_space_data\n",
        "  kx,ky = k_space_data.shape\n",
        "\n",
        "  # Create mask\n",
        "  mask = ghost_kernel(kx, ky, direction)\n",
        "\n",
        "  # Apply mask\n",
        "  k_space_data = k_space_data * mask\n",
        "\n",
        "  # Perform inverse Fourier transform\n",
        "  img_back = np.fft.ifft2(k_space_data)\n",
        "  img_back = np.abs(img_back)\n",
        "\n",
        "  return img_back"
      ],
      "metadata": {
        "id": "eAUlgTfuyaZ8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ghost_dataset(data):\n",
        "  '''\n",
        "  Apply ghosting simulation on a dataset of images.\n",
        "  Each image in the new dataset is a 128x128x4 array.\n",
        "  The first channel is the original image, the second channel is the vertical ghost,\n",
        "  the third channel is the horizontal ghost, and the fourth channel is the diagonal ghost.\n",
        "  Returns a new dataset of shape (num_images, 128, 128, 4).\n",
        "  '''\n",
        "  images = []\n",
        "  for image in tqdm.tqdm(data):\n",
        "      img = np.zeros((128, 128, 4))\n",
        "      img[..., 0] = image\n",
        "      img[..., 1] = apply_ghosting(image, \"vertical\")\n",
        "      img[..., 2] = apply_ghosting(image, \"horizontal\")\n",
        "      img[..., 3] = apply_ghosting(image, \"diagonal\")\n",
        "      images.append(img)\n",
        "  images = np.array(images)\n",
        "  return images\n",
        "\n",
        "\n",
        "#Apply ghosting to training and testing sets\n",
        "training_ghosted = ghost_dataset(X_train)\n",
        "testing_ghosted = ghost_dataset(X_test)"
      ],
      "metadata": {
        "id": "S7vxz0iVzAhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VISUALIZE GHOSTING IMAGES\n",
        "plt.figure(figsize=(10,10))\n",
        "titles = [\"original\", \"vertical\", \"horizontal\", \"diagonal\"]\n",
        "print(\"label = \", y_train[0])\n",
        "for i in range(4):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    plt.title(titles[i])\n",
        "    plt.imshow(training_ghosted[0][...,i],cmap='gray')\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "7groQRlP8Ehb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize new training image: 4 channel image of different blurs\n",
        "plt.imshow(training_ghosted[0])"
      ],
      "metadata": {
        "id": "o-JIaZbyPNEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phsyical Layer - Ghosting"
      ],
      "metadata": {
        "id": "PfQhp62Q1_CQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Ghosting(tf.keras.layers.Layer):\n",
        "    def __init__(self, is_train=False):\n",
        "        super(Ghosting, self).__init__()\n",
        "        self.is_train = is_train\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # initialize weight to be of shape (1,4) of all 1s\n",
        "        self.initializer = tf.keras.initializers.RandomNormal(mean = 1, stddev = .0)\n",
        "        self.img_weights = self.add_weight(shape=(1,4),\n",
        "                                     initializer=self.initializer,\n",
        "                                     trainable=self.is_train,\n",
        "                                     name='mask')\n",
        "    def call(self, inputs):\n",
        "        #multiply image with weights\n",
        "        out = inputs * self.img_weights\n",
        "        #summation of images, remove last channel\n",
        "        out = tf.reduce_sum(out, axis=-1,keepdims=False)\n",
        "        #repeat to 3 channels to accomdate resnet model\n",
        "        out = tf.repeat(out[..., np.newaxis], 3, -1)\n",
        "        return out"
      ],
      "metadata": {
        "id": "FEznBNeJ7eVa"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ResNet50 Model - Transfer learning with ImageNet weights"
      ],
      "metadata": {
        "id": "zMQUKCoQUZgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 4\n",
        "input_size = (128, 128,4)"
      ],
      "metadata": {
        "id": "QvINvHLRUnti"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create ResNet-50 base model for transfer learning, pre-trained on ImageNet\n",
        "base_model = tf.keras.applications.ResNet50(weights = 'imagenet', include_top = False, input_shape = (128,128,3))\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "kShzpJX5UbCF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize mode/layers\n",
        "plot_model(base_model, to_file = \"resnet50_model.png\", show_shapes = True)"
      ],
      "metadata": {
        "id": "lytEm23s2VY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Input layer\n",
        "    tf.keras.layers.Input(input_size),\n",
        "\n",
        "    # Physical layer\n",
        "    Ghosting(is_train=True),\n",
        "\n",
        "    # Transfer learning\n",
        "    base_model,\n",
        "\n",
        "    #Classification Layer\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "YPAXdYNhUjM4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile model with adam optimizer, cross entropy loss\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "tVp4y9miU3kH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "i9N4ydOTWKTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, show_shapes=True, to_file=\"entire_model.png\" )"
      ],
      "metadata": {
        "id": "PuOO7Stf1zCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Weights before Training\n",
        "print(model.layers[0].get_weights())"
      ],
      "metadata": {
        "id": "0Nk6mdmc928O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction of Ghosting Layer before Training\n",
        "subModel = Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "predictions = subModel.predict(training_ghosted)"
      ],
      "metadata": {
        "id": "8P4o68R3-5fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Example Prediction\n",
        "plt.imshow(predictions[0], cmap = 'gray')\n",
        "plt.title('Output Image from Ghosting Layer without Training')\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "1Q0Po4NN-5fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train model for 5 epochs\n",
        "history = model.fit(training_ghosted, y_train, epochs=5,batch_size = 16)"
      ],
      "metadata": {
        "id": "lcQuv6KacAaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test Set Metrics\n",
        "model.evaluate(testing_ghosted,y_test)"
      ],
      "metadata": {
        "id": "Uj4vlaJNe_Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction of Ghosting Layer after Training\n",
        "subModel = Model(inputs=model.input, outputs=model.layers[0].output)\n",
        "predictions = subModel.predict(training_ghosted)"
      ],
      "metadata": {
        "id": "etZ-vxGpjIaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot Example Prediction\n",
        "plt.imshow(predictions[0], cmap = 'gray')\n",
        "plt.title('Output Image from Ghosting Layer after Training')\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "33JkPrx1jIaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print weights after training\n",
        "print(model.layers[0].get_weights())"
      ],
      "metadata": {
        "id": "Ypk5ddHXjIab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix"
      ],
      "metadata": {
        "id": "BheOomnR3MPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate true labels and model predictions\n",
        "true_labels = y_test_new\n",
        "preds = model.predict(testing_ghosted)\n",
        "preds = np.argmax(preds, axis = 1)"
      ],
      "metadata": {
        "id": "XKwDy_L5i8CE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize Confusion Matrix\n",
        "cm = confusion_matrix(true_labels, preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "syQgSo1Fi8CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate Visualizations of Training Loss and Accuracy vs epochs\n",
        "loss = history.history['loss']\n",
        "acc = history.history['accuracy']\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot([i for i in range(1,6)],loss ,label='Training Loss', color = 'orange')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot([i for i in range(1,6)], acc, label='Training Accuracy', color = 'green')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training Accuracy')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "OgBm5D7c3cdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save model weights to reuse later, if needed\n",
        "model.save_weights('final_model_weights.h5')"
      ],
      "metadata": {
        "id": "nkcfh8EKHeG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Referenced Code\n",
        "https://www.kaggle.com/code/abdullahsaida011/brain-tumor-mri-using-efficientnet\n",
        "\n",
        "https://www.kaggle.com/code/tusharnarkhede/brain-tumor-classification\n",
        "\n",
        "https://medium.com/swlh/resnet-with-tensorflow-transfer-learning-13ff0773cf0c"
      ],
      "metadata": {
        "id": "OzZfFCkPyuIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Previous Results\n"
      ],
      "metadata": {
        "id": "OhehmvvNgRHb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Original Train and Testing (Baseline Results):** <br>\n",
        "Epoch 1/5\n",
        " loss: 0.4518 - accuracy: 0.8692 - val_loss: 0.3713 - val_accuracy: 0.8664 <br>\n",
        "Epoch 2/5\n",
        "loss: 0.0392 - accuracy: 0.9876 - val_loss: 0.2172 - val_accuracy: 0.9237 <br>\n",
        "Epoch 3/5\n",
        "loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.2319 - val_accuracy: 0.9160 <br>\n",
        "Epoch 4/5\n",
        " loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9237<br>\n",
        "Epoch 5/5\n",
        " loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9237 <br>\n",
        "TEST SET: 41/41 [==============================] - 5s 126ms/step - loss: 0.2024 - accuracy: **0.9375**\n",
        "[0.20240727066993713, 0.9374523162841797]<br>\n",
        "Confusion Matrix: array([[271,  28,   0,   1],\n",
        "       [ 10, 290,   4,   2],\n",
        "       [  0,   1, 404,   0],\n",
        "       [  4,  32,   0, 264]])"
      ],
      "metadata": {
        "id": "wgs39u3eI5OE"
      }
    }
  ]
}